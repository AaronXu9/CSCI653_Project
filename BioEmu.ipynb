{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLoa2lUhX9gu"
      },
      "source": [
        "# **Biomolecular Emulator (BioEmu) in ColabFold**\n",
        "<img src=\"https://github.com/microsoft/bioemu/raw/main/assets/emu.png\" height=\"130\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "[BioEmu](https://github.com/microsoft/bioemu) is a framework for emulating biomolecular dynamics and integrating structural prediction tools to accelerate research in structural biology and protein engineering. This notebook uses BioEmu with ColabFold to generate the MSA and identify cluster conformations using Foldseek.\n",
        "\n",
        "\n",
        "\n",
        "For more details, please read the [BioEmu Preprint](https://www.biorxiv.org/content/10.1101/2024.12.05.626885v2).\n",
        "\n",
        "\n",
        "## To run\n",
        "Either run each cell sequentially, or click on `Runtime -> Run All` after choosing the desired sampling config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TWM2qzfEYMaL"
      },
      "outputs": [],
      "source": [
        "#@title Sample with following config\n",
        "#@markdown - `sequence`: Monomer sequence to sample\n",
        "sequence = \"MGCTLSAEDKAAVERSKMIDRNLREDGEKAAREVKLLLLGAGESGKNTIVKQMKIIHEAGYSEEECKQYKAVVYSNTIQSIIAIIRAMGRLKIDFGDSARADDARQLFVLAGAAEEGFMTAELAGVIKRLWKDSGVQACFNRSREYQLNDSAAYYLNDLDRIAQPNYIPTQQDVLRTRVKTTGIVETHFTFKDLHFKMFDVGAQRSERKKWIHCFEGVTAIIFCVALSDYDLVLAEDEEMNRMHASMKLFDSICNNKWFTDTSIILFLNKKDLFEEKIKKSPLTICYPEYAGSNTYEEAAAYIQCQFEDLNKRKDTKEIYTHFTCSTDTKNVQFVFDAVTDVIIKNNLKDCGLF\"  #@param {type:\"string\"}\n",
        "#@markdown - `num_samples`: Number of samples requested\n",
        "num_samples = 5  #@param {type:\"integer\"}\n",
        "#@markdown - `jobname`: Name assigned to this job\n",
        "jobname = \"d2r_full\"  #@param {type:\"string\"}\n",
        "#@markdown - `filter_samples`: Whether to filter unphysical samples (e.g., those containing chain breaks) from the written samples\n",
        "filter_samples = True #@param {type:\"boolean\"}\n",
        "# #@param {type:\"boolean\"}\n",
        "# ------------------------\n",
        "# Copied logic from ColabFold\n",
        "# ------------------------\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "\n",
        "def add_hash(x, seq):\n",
        "    \"\"\"Append a short SHA-1 hash of seq to x.\"\"\"\n",
        "    return x + \"_\" + hashlib.sha1(seq.encode()).hexdigest()[:5]\n",
        "\n",
        "def folder_is_free(folder):\n",
        "    \"\"\"Return True if folder doesn't exist.\"\"\"\n",
        "    return not os.path.exists(folder)\n",
        "\n",
        "jobname_clean = re.sub(r'\\W+', '', jobname)\n",
        "sequence = \"\".join(sequence.split())\n",
        "jobname = add_hash(jobname_clean, sequence)\n",
        "\n",
        "if not folder_is_free(jobname):\n",
        "    n = 0\n",
        "    while not folder_is_free(f\"{jobname}_{n}\"):\n",
        "        n += 1\n",
        "    jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "output_dir = os.path.join(\"/content\", jobname)\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "7bAv6hU6Nedi",
        "outputId": "5f4ec912-1ca8-48b1-cdc1-9ba57cfd975d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BioEmu is already installed.\n",
            "✓ bioemu version: installed\n",
            "✓ bioemu location: /usr/local/lib/python3.12/dist-packages/bioemu/__init__.py\n",
            "✓ Patched ColabFold setup script\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "_marker_file = '/content/.BIOEMU_INSTALLED'\n",
        "\n",
        "# Check if we need to install\n",
        "need_install = not os.path.exists(_marker_file)\n",
        "\n",
        "if need_install:\n",
        "    print(\"=\"*60)\n",
        "    print(\"Installing BioEmu and dependencies...\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Install bioemu - let pip handle all dependencies including PyTorch\n",
        "    print(\"\\n[1/3] Installing bioemu package...\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'bioemu[md]==0.1.6'], check=True)\n",
        "    \n",
        "    # Download foldseek\n",
        "    print(\"[2/3] Downloading foldseek...\")\n",
        "    if not os.path.exists('/content/foldseek'):\n",
        "        subprocess.run('wget -q https://mmseqs.com/foldseek/foldseek-linux-avx2.tar.gz && tar xzf foldseek-linux-avx2.tar.gz', shell=True, check=True)\n",
        "    \n",
        "    print(\"[3/3] Installation complete!\")\n",
        "    \n",
        "    # Create marker\n",
        "    with open(_marker_file, 'w') as f:\n",
        "        f.write('installed')\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"⚠️  IMPORTANT: Restart the runtime now!\")\n",
        "    print(\"    Go to: Runtime > Restart runtime\")\n",
        "    print(\"    Then run this cell again.\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"BioEmu is already installed.\")\n",
        "    \n",
        "    # Verify the import works\n",
        "    try:\n",
        "        import bioemu\n",
        "        print(f\"✓ bioemu version: {bioemu.__version__ if hasattr(bioemu, '__version__') else 'installed'}\")\n",
        "        print(f\"✓ bioemu location: {bioemu.__file__}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"✗ Import error: {e}\")\n",
        "        print(\"Try: Runtime > Restart runtime, then run this cell again\")\n",
        "\n",
        "# Always set environment variables\n",
        "os.environ['CONDA_PREFIX'] = '/usr'\n",
        "os.environ['CONDA_PREFIX_1'] = '/usr'\n",
        "os.environ['CONDA_DEFAULT_ENV'] = 'base'\n",
        "\n",
        "# Patch the setup.sh for ColabFold (needed for MSA generation)\n",
        "# Fixed version: properly install into venv and expand glob for patch paths\n",
        "python_exec = sys.executable\n",
        "\n",
        "setup_sh_content = f'''#!/bin/bash\n",
        "set -ex\n",
        "\n",
        "echo \"Setting up colabfold...\"\n",
        "VENV_FOLDER=$1\n",
        "\n",
        "# Create venv without pip (avoids ensurepip issues on Colab)\n",
        "{python_exec} -m venv --without-pip ${{VENV_FOLDER}}\n",
        "\n",
        "# Install pip using get-pip.py\n",
        "curl -sS https://bootstrap.pypa.io/get-pip.py | ${{VENV_FOLDER}}/bin/python\n",
        "\n",
        "# Install uv in the venv\n",
        "${{VENV_FOLDER}}/bin/pip install uv\n",
        "\n",
        "# Install colabfold INTO THE VENV (not system)\n",
        "${{VENV_FOLDER}}/bin/uv pip install --python ${{VENV_FOLDER}}/bin/python 'colabfold[alphafold-minus-jax]==1.5.4'\n",
        "${{VENV_FOLDER}}/bin/uv pip install --python ${{VENV_FOLDER}}/bin/python --force-reinstall \"jax[cuda12]==0.4.35\" \"numpy==1.26.4\"\n",
        "${{VENV_FOLDER}}/bin/uv pip install --python ${{VENV_FOLDER}}/bin/python --force-reinstall \\\\\n",
        "    \"nvidia-cublas-cu12==12.8.4.1\" \\\\\n",
        "    \"nvidia-cuda-cupti-cu12==12.8.90\" \\\\\n",
        "    \"nvidia-cuda-nvcc-cu12==12.8.93\" \\\\\n",
        "    \"nvidia-cuda-runtime-cu12==12.8.90\" \\\\\n",
        "    \"nvidia-cudnn-cu12==9.8.0.87\" \\\\\n",
        "    \"nvidia-cufft-cu12==11.3.3.83\" \\\\\n",
        "    \"nvidia-cusolver-cu12==11.7.3.90\" \\\\\n",
        "    \"nvidia-cusparse-cu12==12.5.8.93\" \\\\\n",
        "    \"nvidia-nccl-cu12==2.26.2.post1\" \\\\\n",
        "    \"nvidia-nvjitlink-cu12==12.8.93\"\n",
        "\n",
        "# Patch colabfold install\n",
        "echo \"Patching colabfold installation...\"\n",
        "SCRIPT_DIR=$( cd -- \"$( dirname -- \"${{BASH_SOURCE[0]}}\" )\" &> /dev/null && pwd )\n",
        "\n",
        "# Find the actual site-packages directory (expand the glob properly)\n",
        "SITE_PACKAGES_DIR=$(ls -d ${{VENV_FOLDER}}/lib/python3.*/site-packages 2>/dev/null | head -1)\n",
        "\n",
        "if [ -z \"$SITE_PACKAGES_DIR\" ]; then\n",
        "    echo \"ERROR: Could not find site-packages directory\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Site packages directory: $SITE_PACKAGES_DIR\"\n",
        "\n",
        "# Apply patches\n",
        "patch \"$SITE_PACKAGES_DIR/alphafold/model/modules.py\" \"$SCRIPT_DIR/modules.patch\"\n",
        "patch \"$SITE_PACKAGES_DIR/colabfold/batch.py\" \"$SCRIPT_DIR/batch.patch\"\n",
        "\n",
        "touch ${{VENV_FOLDER}}/.COLABFOLD_PATCHED\n",
        "echo \"Colabfold installation complete!\"\n",
        "'''\n",
        "\n",
        "try:\n",
        "    import importlib.util\n",
        "    spec = importlib.util.find_spec(\"bioemu\")\n",
        "    if spec and spec.origin:\n",
        "        setup_sh_path = os.path.join(os.path.dirname(spec.origin), 'colabfold_setup', 'setup.sh')\n",
        "        if os.path.exists(os.path.dirname(setup_sh_path)):\n",
        "            with open(setup_sh_path, 'w') as f:\n",
        "                f.write(setup_sh_content)\n",
        "            print(f\"✓ Patched ColabFold setup script\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not patch setup.sh: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ColabFold directory is clean or doesn't exist\n"
          ]
        }
      ],
      "source": [
        "# Check ColabFold installation status\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "colabfold_dir = '/root/.bioemu_colabfold'\n",
        "colabfold_batch = os.path.join(colabfold_dir, 'bin', 'colabfold_batch')\n",
        "patched_marker = os.path.join(colabfold_dir, '.COLABFOLD_PATCHED')\n",
        "\n",
        "if os.path.exists(colabfold_batch):\n",
        "    print(f\"✓ ColabFold is installed at {colabfold_dir}\")\n",
        "    if os.path.exists(patched_marker):\n",
        "        print(\"✓ ColabFold is fully patched and ready\")\n",
        "    else:\n",
        "        print(\"⚠ ColabFold installed but not marked as patched\")\n",
        "        print(\"  If you see errors, run Cell 4 again to re-patch, then delete this folder and re-run\")\n",
        "elif os.path.exists(colabfold_dir):\n",
        "    print(f\"⚠ ColabFold directory exists but may be incomplete\")\n",
        "    print(f\"  Run Cell 4 to fix the installation\")\n",
        "else:\n",
        "    print(\"ColabFold not installed yet - it will be installed when you run BioEmu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 <command> [options]\n",
            "\n",
            "Commands:\n",
            "  install                     Install packages.\n",
            "  download                    Download packages.\n",
            "  uninstall                   Uninstall packages.\n",
            "  freeze                      Output installed packages in requirements format.\n",
            "  inspect                     Inspect the python environment.\n",
            "  list                        List installed packages.\n",
            "  show                        Show information about installed packages.\n",
            "  check                       Verify installed packages have compatible dependencies.\n",
            "  config                      Manage local and global configuration.\n",
            "  search                      Search PyPI for packages.\n",
            "  cache                       Inspect and manage pip's wheel cache.\n",
            "  index                       Inspect information available from package indexes.\n",
            "  wheel                       Build wheels from your requirements.\n",
            "  hash                        Compute hashes of package archives.\n",
            "  completion                  A helper command used for command completion.\n",
            "  debug                       Show information useful for debugging.\n",
            "  help                        Show help for commands.\n",
            "\n",
            "General Options:\n",
            "  -h, --help                  Show help.\n",
            "  --debug                     Let unhandled exceptions propagate outside the\n",
            "                              main subroutine, instead of logging them to\n",
            "                              stderr.\n",
            "  --isolated                  Run pip in an isolated mode, ignoring\n",
            "                              environment variables and user configuration.\n",
            "  --require-virtualenv        Allow pip to only run in a virtual environment;\n",
            "                              exit with an error otherwise.\n",
            "  --python <python>           Run pip with the specified Python interpreter.\n",
            "  -v, --verbose               Give more output. Option is additive, and can be\n",
            "                              used up to 3 times.\n",
            "  -V, --version               Show version and exit.\n",
            "  -q, --quiet                 Give less output. Option is additive, and can be\n",
            "                              used up to 3 times (corresponding to WARNING,\n",
            "                              ERROR, and CRITICAL logging levels).\n",
            "  --log <path>                Path to a verbose appending log.\n",
            "  --no-input                  Disable prompting for input.\n",
            "  --keyring-provider <keyring_provider>\n",
            "                              Enable the credential lookup via the keyring\n",
            "                              library if user input is allowed. Specify which\n",
            "                              mechanism to use [disabled, import, subprocess].\n",
            "                              (default: disabled)\n",
            "  --proxy <proxy>             Specify a proxy in the form\n",
            "                              scheme://[user:passwd@]proxy.server:port.\n",
            "  --retries <retries>         Maximum number of retries each connection should\n",
            "                              attempt (default 5 times).\n",
            "  --timeout <sec>             Set the socket timeout (default 15 seconds).\n",
            "  --exists-action <action>    Default action when a path already exists:\n",
            "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\n",
            "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\n",
            "                              even though it does not have valid or any HTTPS.\n",
            "  --cert <path>               Path to PEM-encoded CA certificate bundle. If\n",
            "                              provided, overrides the default. See 'SSL\n",
            "                              Certificate Verification' in pip documentation\n",
            "                              for more information.\n",
            "  --client-cert <path>        Path to SSL client certificate, a single file\n",
            "                              containing the private key and the certificate\n",
            "                              in PEM format.\n",
            "  --cache-dir <dir>           Store the cache data in <dir>.\n",
            "  --no-cache-dir              Disable the cache.\n",
            "  --disable-pip-version-check\n",
            "                              Don't periodically check PyPI to determine\n",
            "                              whether a new version of pip is available for\n",
            "                              download. Implied with --no-index.\n",
            "  --no-color                  Suppress colored output.\n",
            "  --no-python-version-warning\n",
            "                              Silence deprecation warnings for upcoming\n",
            "                              unsupported Pythons.\n",
            "  --use-feature <feature>     Enable new functionality, that may be backward\n",
            "                              incompatible.\n",
            "  --use-deprecated <feature>  Enable deprecated functionality, that will be\n",
            "                              removed in the future.\n"
          ]
        }
      ],
      "source": [
        "! /usr/local/bin/pip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RuPiufqgSeH_"
      },
      "outputs": [],
      "source": [
        "sequence = '/content/rcsb_pdb_7JVR.fasta'\n",
        "sequence = 'MGCTLSAEDKAAVERSKMIDRNLREDGEKAAREVKLLLLGAGESGKNTIVKQMKIIHEAGYSEEECKQYKAVVYSNTIQSIIAIIRAMGRLKIDFGDSARADDARQLFVLAGAAEEGFMTAELAGVIKRLWKDSGVQACFNRSREYQLNDSAAYYLNDLDRIAQPNYIPTQQDVLRTRVKTTGIVETHFTFKDLHFKMFDVGAQRSERKKWIHCFEGVTAIIFCVALSDYDLVLAEDEEMNRMHASMKLFDSICNNKWFTDTSIILFLNKKDLFEEKIKKSPLTICYPEYAGSNTYEEAAAYIQCQFEDLNKRKDTKEIYTHFTCSTDTKNVQFVFDAVTDVIIKNNLKDCGLFDYKDDDDAKLQTMHHHHHHHHHHHHHHHADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPDSPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLASENLYFQGGTMDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHCMGSLLQSELDQLRQEAEQLKNQIRDARKACADATLSQITNNIDPVGRIQMRTRRTLRGHLAKIYAMHWGTDSRLLVSASQDGKLIIWDSYTTNKVHAIPLRSSWVMTCAYAPSGNYVACGGLDNICSIYNLKTREGNVRVSRELAGHTGYLSCCRFLDDNQIVTSSGDTTCALWDIETGQQTTTFTGHTGDVMSLSLAPDTRLFVSGACDASAKLWDVREGMCRQTFTGHESDINAICFFPNGNAFATGSDDATCRLFDLRADQELMTYSHDNIICGITSVSFSKSGRLLLAGYDDFNCNVWDALKADRAGVLAGHDNRVSCLGVTDDGMAVATGSWDSFLKIWNGSSMASNNTASIAQARKLVEQLKMEANIDRIKVSKAAADLMAYCEAHAKEDPLLTPVPASENPFREKKFFCAILDVQLVESGGGLVQPGGSRKLSCSASGFAFSSFGMHWVRQAPEKGLEWVAYISSGSGTIYYADTVKGRFTISRDDPKNTLFLQMTSLRSEDTAMYYCVRSIYYYGSSPFDFWGQGTTLTVSSGGGGSGGGGSGGGGSDIVMTQATSSVPVTPGESVSISCRSSKSLLHSNGNTYLYWFLQRPGQSPQLLIYRMSNLASGVPDRFSGSGSGTAFTLTISRLEAEDVGVYYCMQHLEYPLTFGAGTKLELKGSLEVLFQGPAAAHHHHHHHH'\n",
        "jobname = 'd2r_2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v0_pgb5o9r95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MGCTLSAEDKAAVERSKMIDRNLREDGEKAAREVKLLLLGAGESGKNTIVKQMKIIHEAGYSEEECKQYKAVVYSNTIQSIIAIIRAMGRLKIDFGDSARADDARQLFVLAGAAEEGFMTAELAGVIKRLWKDSGVQACFNRSREYQLNDSAAYYLNDLDRIAQPNYIPTQQDVLRTRVKTTGIVETHFTFKDLHFKMFDVGAQRSERKKWIHCFEGVTAIIFCVALSDYDLVLAEDEEMNRMHASMKLFDSICNNKWFTDTSIILFLNKKDLFEEKIKKSPLTICYPEYAGSNTYEEAAAYIQCQFEDLNKRKDTKEIYTHFTCSTDTKNVQFVFDAVTDVIIKNNLKDCGLFDYKDDDDAKLQTMHHHHHHHHHHHHHHHADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPDSPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLASENLYFQGGTMDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHCMGSLLQSELDQLRQEAEQLKNQIRDARKACADATLSQITNNIDPVGRIQMRTRRTLRGHLAKIYAMHWGTDSRLLVSASQDGKLIIWDSYTTNKVHAIPLRSSWVMTCAYAPSGNYVACGGLDNICSIYNLKTREGNVRVSRELAGHTGYLSCCRFLDDNQIVTSSGDTTCALWDIETGQQTTTFTGHTGDVMSLSLAPDTRLFVSGACDASAKLWDVREGMCRQTFTGHESDINAICFFPNGNAFATGSDDATCRLFDLRADQELMTYSHDNIICGITSVSFSKSGRLLLAGYDDFNCNVWDALKADRAGVLAGHDNRVSCLGVTDDGMAVATGSWDSFLKIWNGSSMASNNTASIAQARKLVEQLKMEANIDRIKVSKAAADLMAYCEAHAKEDPLLTPVPASENPFREKKFFCAILDVQLVESGGGLVQPGGSRKLSCSASGFAFSSFGMHWVRQAPEKGLEWVAYISSGSGTIYYADTVKGRFTISRDDPKNTLFLQMTSLRSEDTAMYYCVRSIYYYGSSPFDFWGQGTTLTVSSGGGGSGGGGSGGGGSDIVMTQATSSVPVTPGESVSISCRSSKSLLHSNGNTYLYWFLQRPGQSPQLLIYRMSNLASGVPDRFSGSGSGTAFTLTISRLEAEDVGVYYCMQHLEYPLTFGAGTKLELKGSLEVLFQGPAAAHHHHHHHH'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TYvJwSLMpd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "WARNING:bioemu.sample:Sequence MGCTLSAEDKAAVERSKMIDRNLREDGEKAAREVKLLLLGAGESGKNTIVKQMKIIHEAGYSEEECKQYKAVVYSNTIQSIIAIIRAMGRLKIDFGDSARADDARQLFVLAGAAEEGFMTAELAGVIKRLWKDSGVQACFNRSREYQLNDSAAYYLNDLDRIAQPNYIPTQQDVLRTRVKTTGIVETHFTFKDLHFKMFDVGAQRSERKKWIHCFEGVTAIIFCVALSDYDLVLAEDEEMNRMHASMKLFDSICNNKWFTDTSIILFLNKKDLFEEKIKKSPLTICYPEYAGSNTYEEAAAYIQCQFEDLNKRKDTKEIYTHFTCSTDTKNVQFVFDAVTDVIIKNNLKDCGLFDYKDDDDAKLQTMHHHHHHHHHHHHHHHADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPDSPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLASENLYFQGGTMDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHCMGSLLQSELDQLRQEAEQLKNQIRDARKACADATLSQITNNIDPVGRIQMRTRRTLRGHLAKIYAMHWGTDSRLLVSASQDGKLIIWDSYTTNKVHAIPLRSSWVMTCAYAPSGNYVACGGLDNICSIYNLKTREGNVRVSRELAGHTGYLSCCRFLDDNQIVTSSGDTTCALWDIETGQQTTTFTGHTGDVMSLSLAPDTRLFVSGACDASAKLWDVREGMCRQTFTGHESDINAICFFPNGNAFATGSDDATCRLFDLRADQELMTYSHDNIICGITSVSFSKSGRLLLAGYDDFNCNVWDALKADRAGVLAGHDNRVSCLGVTDDGMAVATGSWDSFLKIWNGSSMASNNTASIAQARKLVEQLKMEANIDRIKVSKAAADLMAYCEAHAKEDPLLTPVPASENPFREKKFFCAILDVQLVESGGGLVQPGGSRKLSCSASGFAFSSFGMHWVRQAPEKGLEWVAYISSGSGTIYYADTVKGRFTISRDDPKNTLFLQMTSLRSEDTAMYYCVRSIYYYGSSPFDFWGQGTTLTVSSGGGGSGGGGSGGGGSDIVMTQATSSVPVTPGESVSISCRSSKSLLHSNGNTYLYWFLQRPGQSPQLLIYRMSNLASGVPDRFSGSGSGTAFTLTISRLEAEDVGVYYCMQHLEYPLTFGAGTKLELKGSLEVLFQGPAAAHHHHHHHH may be too long. Attempting with batch_size = 1.\n",
            "WARNING:bioemu.sample:Sequence MGCTLSAEDKAAVERSKMIDRNLREDGEKAAREVKLLLLGAGESGKNTIVKQMKIIHEAGYSEEECKQYKAVVYSNTIQSIIAIIRAMGRLKIDFGDSARADDARQLFVLAGAAEEGFMTAELAGVIKRLWKDSGVQACFNRSREYQLNDSAAYYLNDLDRIAQPNYIPTQQDVLRTRVKTTGIVETHFTFKDLHFKMFDVGAQRSERKKWIHCFEGVTAIIFCVALSDYDLVLAEDEEMNRMHASMKLFDSICNNKWFTDTSIILFLNKKDLFEEKIKKSPLTICYPEYAGSNTYEEAAAYIQCQFEDLNKRKDTKEIYTHFTCSTDTKNVQFVFDAVTDVIIKNNLKDCGLFDYKDDDDAKLQTMHHHHHHHHHHHHHHHADLEDNWETLNDNLKVIEKADNAAQVKDALTKMRAAALDAQKATPPKLEDKSPDSPEMKDFRHGFDILVGQIDDALKLANEGKVKEAQAAAEQLKTTRNAYIQKYLASENLYFQGGTMDPLNLSWYDDDLERQNWSRPFNGSDGKADRPHYNYYATLLTLLIAVIVFGNVLVCMAVSREKALQTTTNYLIVSLAVADLLVATLVMPWVVYLEVVGEWKFSRIHCDIFVTLDVMMCTASILNLCAISIDRYTAVAMPMLYNTRYSSKRRVTVMISIVWVLSFTISCPLLFGLNNADQNECIIANPAFVVYSSIVSFYVPFIVTLLVYIKIYIVLRRRRKRVNTKRSSRAFRAHLRAPLKGNCTHPEDMKLCTVIMKSNGSFPVNRRRVEAARRAQELEMEMLSSTSPPERTRYSPIPPSHHQLTLPDPSHHGLHSTPDSPAKPEKNGHAKDHPKIAKIFEIQTMPNGKTRTSLKTMSRRKLSQQKEKKATQMLAIVLGVFIICWLPFFITHILNIHCDCNIPPVLYSAFTWLGYVNSAVNPIIYTTFNIEFRKAFLKILHCMGSLLQSELDQLRQEAEQLKNQIRDARKACADATLSQITNNIDPVGRIQMRTRRTLRGHLAKIYAMHWGTDSRLLVSASQDGKLIIWDSYTTNKVHAIPLRSSWVMTCAYAPSGNYVACGGLDNICSIYNLKTREGNVRVSRELAGHTGYLSCCRFLDDNQIVTSSGDTTCALWDIETGQQTTTFTGHTGDVMSLSLAPDTRLFVSGACDASAKLWDVREGMCRQTFTGHESDINAICFFPNGNAFATGSDDATCRLFDLRADQELMTYSHDNIICGITSVSFSKSGRLLLAGYDDFNCNVWDALKADRAGVLAGHDNRVSCLGVTDDGMAVATGSWDSFLKIWNGSSMASNNTASIAQARKLVEQLKMEANIDRIKVSKAAADLMAYCEAHAKEDPLLTPVPASENPFREKKFFCAILDVQLVESGGGLVQPGGSRKLSCSASGFAFSSFGMHWVRQAPEKGLEWVAYISSGSGTIYYADTVKGRFTISRDDPKNTLFLQMTSLRSEDTAMYYCVRSIYYYGSSPFDFWGQGTTLTVSSGGGGSGGGGSGGGGSDIVMTQATSSVPVTPGESVSISCRSSKSLLHSNGNTYLYWFLQRPGQSPQLLIYRMSNLASGVPDRFSGSGSGTAFTLTISRLEAEDVGVYYCMQHLEYPLTFGAGTKLELKGSLEVLFQGPAAAHHHHHHHH may be too long. Attempting with batch_size = 1.\n",
            "INFO:bioemu.get_embeds:Using cached embeddings in /root/.bioemu_embeds_cache.\n",
            "INFO:bioemu.get_embeds:Using cached embeddings in /root/.bioemu_embeds_cache.\n",
            "INFO:bioemu.get_embeds:Using cached embeddings in /root/.bioemu_embeds_cache.\n",
            "INFO:bioemu.get_embeds:Using cached embeddings in /root/.bioemu_embeds_cache.\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "output_type": "error",
          "traceback": [
            "Stackprinter failed while formatting <FrameInfo /tmp/ipython-input-2672197154.py, line 11, scope <cell line: 0>>:\n  File \"/usr/local/lib/python3.12/dist-packages/stackprinter/frame_formatting.py\", line 225, in select_scope\n    raise Exception(\"Picked an invalid source context: %s\" % info)\nException: Picked an invalid source context: [11], [], dict_keys([1])\n\nSo here is your original traceback at least:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipython-input-2672197154.py\", line 11, in <cell line: 0>\n    sample(sequence=sequence, num_samples=num_samples, output_dir=output_dir, filter_samples=filter_samples)\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/bioemu/sample.py\", line 189, in main\n    save_pdb_and_xtc(\n  File \"/usr/local/lib/python3.12/dist-packages/bioemu/convert_chemgraph.py\", line 457, in save_pdb_and_xtc\n    traj.superpose(reference=traj, frame=0)\n  File \"/usr/local/lib/python3.12/dist-packages/mdtraj/core/trajectory.py\", line 1097, in superpose\n    reference.xyz[frame, ref_atom_indices, :],\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIndexError: index 0 is out of bounds for axis 0 with size 0\n"
          ]
        }
      ],
      "source": [
        "#@title Run BioEmu\n",
        "import os\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['CONDA_PREFIX'] = '/usr'\n",
        "os.environ['CONDA_PREFIX_1'] = '/usr'\n",
        "os.environ['CONDA_DEFAULT_ENV'] = 'base'\n",
        "\n",
        "from bioemu.sample import main as sample\n",
        "\n",
        "print(f\"Sequence length: {len(sequence)} residues\")\n",
        "\n",
        "# For very long sequences (>500 residues), filtering often removes all samples\n",
        "# Disable filtering for long sequences to get results\n",
        "if len(sequence) > 500:\n",
        "    print(\"⚠️ Long sequence detected - disabling filter_samples to avoid empty results\")\n",
        "    use_filter = False\n",
        "else:\n",
        "    use_filter = filter_samples\n",
        "\n",
        "print(f\"Using filter_samples={use_filter}\")\n",
        "\n",
        "output_dir = f'/content/{jobname}'\n",
        "sample(sequence=sequence, num_samples=num_samples, output_dir=output_dir, filter_samples=use_filter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug: Check what was generated\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "if os.path.exists(output_dir):\n",
        "    files = os.listdir(output_dir)\n",
        "    print(f\"Files in output: {files}\")\n",
        "    \n",
        "    # Check for .npz batch files (intermediate samples)\n",
        "    npz_files = glob(os.path.join(output_dir, \"*.npz\"))\n",
        "    print(f\"NPZ batch files: {len(npz_files)}\")\n",
        "    \n",
        "    # If there are npz files, check their contents\n",
        "    if npz_files:\n",
        "        import numpy as np\n",
        "        for f in npz_files[:2]:  # Check first 2\n",
        "            data = np.load(f)\n",
        "            print(f\"  {os.path.basename(f)}: keys={list(data.keys())}\")\n",
        "else:\n",
        "    print(\"Output directory doesn't exist yet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "collapsed": true,
        "id": "GbNRxHwgWzfF",
        "outputId": "da367a09-39b8-4628-b0f9-9b3f1da136cd"
      },
      "outputs": [],
      "source": [
        "#@title Write samples and run `foldseek`\n",
        "#@markdown - `n_write_samples`: Number of samples to randomly select for clustering. Set to `-1` to select all available samples\n",
        "#@markdown - `tmscore_threshold`: TM-score threshold used for foldseek clustering\n",
        "#@markdown - `coverage_threshold`: Coverage threshold used for foldseek clustering\n",
        "#@markdown - `seq_id`: Sequence identity threshold used for foldseek clustering\n",
        "\n",
        "n_write_samples = -1 #@param {type:\"integer\"}\n",
        "tmscore_threshold = 0.6 #@param {type: \"number\"}\n",
        "coverage_threshold = 0.7 #@param {type: \"number\"}\n",
        "seq_id = 0.95 #@param {type: \"number\"}\n",
        "\n",
        "import numpy as np\n",
        "import mdtraj\n",
        "\n",
        "_py3dmol_installed_file = '/content/.py3dmol'\n",
        "if not os.path.exists(_py3dmol_installed_file):\n",
        "    os.system('uv pip install py3Dmol')\n",
        "    os.system(f\"touch {_py3dmol_installed_file}\")\n",
        "\n",
        "import py3Dmol\n",
        "pdb_sample_dir = os.path.join('/content', 'pdb_samples')\n",
        "os.makedirs(pdb_sample_dir, exist_ok=True)\n",
        "\n",
        "def write_some_samples(topology_file: str, trajectory_file: str, output_dir:str, n_samples: int) -> None:\n",
        "    traj = mdtraj.load(trajectory_file, top=topology_file)\n",
        "    assert traj.n_frames >= n_samples\n",
        "    if n_samples == -1:\n",
        "        sample_indices = np.arange(traj.n_frames)\n",
        "    else:\n",
        "        sample_indices = np.random.choice(np.arange(traj.n_frames), size=n_samples, replace=False)\n",
        "    for idx in sample_indices:\n",
        "        traj[idx].save_pdb(os.path.join(output_dir, f'sample_{idx}.pdb'))\n",
        "\n",
        "\n",
        "topology_file = os.path.join(output_dir, \"topology.pdb\")\n",
        "trajectory_file = os.path.join(output_dir, \"samples.xtc\")\n",
        "\n",
        "write_some_samples(topology_file=topology_file,\n",
        "                   trajectory_file=trajectory_file,\n",
        "                   output_dir=pdb_sample_dir,\n",
        "                   n_samples=n_write_samples)\n",
        "\n",
        "# Foldseek\n",
        "import os\n",
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def parse_foldseek_cluster_results(cluster_table_path: str) -> dict[int, list[str]]:\n",
        "    \"\"\"\n",
        "    Parses the result of foldseek clustering\n",
        "\n",
        "    Args:\n",
        "        cluster_table: path of the output cluster table from foldseek\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping cluster indices to members\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    cluster_table = pd.read_csv(cluster_table_path, sep=r\"\\s+\", header=None)\n",
        "\n",
        "    cluster_idx_to_members = {}\n",
        "\n",
        "    for index, group in enumerate(cluster_table.groupby(0)):\n",
        "        cluster_idx_to_members[index] = sorted(list(group[1][1]))\n",
        "\n",
        "    return cluster_idx_to_members\n",
        "\n",
        "\n",
        "def foldseek_cluster(\n",
        "    input_dir: str,\n",
        "    out_prefix: str | None = None,\n",
        "    tmscore_threshold: float = 0.7,\n",
        "    coverage_threshold: float = 0.9,\n",
        "    seq_id: float = 0.7,\n",
        "    coverage_mode: int = 1,\n",
        ") -> dict[int, set[str]]:\n",
        "    \"\"\"\n",
        "    Runs foldseek easy cluster\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): input directory with .cif or .pdb files\n",
        "        out_prefix (str | None): the prefix of the output files, if None a temporary directory will be used\n",
        "        tmscore_threshold (float): the tm-score threshold used for clustering\n",
        "        coverage_threshold (float): the coverage threshold used for clustering\n",
        "        seq_id (float): the sequence identity threshold used for clustering\n",
        "        coverage_mode (int): mode used by mmseqs/foldseek to compute coverage\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping cluster indices to members\n",
        "    \"\"\"\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "\n",
        "        with tempfile.TemporaryDirectory() as temp_out_dir:\n",
        "            if out_prefix is None:\n",
        "                out_prefix = os.path.join(temp_out_dir, \"output\")\n",
        "\n",
        "            res = subprocess.run(\n",
        "                \"/content/foldseek/bin/foldseek easy-cluster \"\n",
        "                + input_dir\n",
        "                + \" \"\n",
        "                + out_prefix\n",
        "                + \" \"\n",
        "                + temp_dir\n",
        "                + \" -c  \"\n",
        "                + str(coverage_threshold)\n",
        "                + \" --min-seq-id \"\n",
        "                + str(seq_id)\n",
        "                + \" --tmscore-threshold \"\n",
        "                + str(tmscore_threshold)\n",
        "                + \" --cov-mode \"\n",
        "                + str(coverage_mode)\n",
        "                + \" --single-step-clustering\",\n",
        "                shell=True,\n",
        "            )\n",
        "            assert res.returncode == 0, \"Something went wrong with foldseek\"\n",
        "\n",
        "            cluster_idx_to_members = parse_foldseek_cluster_results(out_prefix + \"_cluster.tsv\")\n",
        "\n",
        "    return cluster_idx_to_members\n",
        "\n",
        "!chmod +x '/content/foldseek/bin/foldseek'\n",
        "\n",
        "# Get foldseek clusters\n",
        "clusters = foldseek_cluster(input_dir=pdb_sample_dir, tmscore_threshold=tmscore_threshold,\n",
        "                            coverage_threshold=coverage_threshold, seq_id=seq_id)\n",
        "n_clusters = len(clusters)\n",
        "print(f'{n_clusters} clusters detected')\n",
        "\n",
        "# Write foldseek clusters to output dir\n",
        "import json\n",
        "\n",
        "with open(os.path.join(output_dir, 'foldseek_clusters.json'), 'w') as json_handle:\n",
        "    json.dump(clusters, json_handle)\n",
        "\n",
        "\n",
        "# Write XTC with one sample per cluster only\n",
        "cluster_trajs = []\n",
        "for _cluster_idx, samples in clusters.items():\n",
        "    sample = list(samples)[0] # Choose first sample in cluster\n",
        "    pdb_file = os.path.join(pdb_sample_dir, f\"{sample}.pdb\")\n",
        "    traj = mdtraj.load_pdb(pdb_file)\n",
        "    cluster_trajs.append(traj)\n",
        "joint_traj = mdtraj.join(cluster_trajs)\n",
        "cluster_topology_file = os.path.join(output_dir, \"clustered_topology.pdb\")\n",
        "cluster_trajectory_file = os.path.join(output_dir, \"clustered_samples.xtc\")\n",
        "joint_traj[0].save_pdb(cluster_topology_file)\n",
        "joint_traj.save_xtc(cluster_trajectory_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLWzZQYAcVzr"
      },
      "outputs": [],
      "source": [
        "#@title Display structure\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "import py3Dmol\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Create interactive widgets for cluster and sample selection.\n",
        "cluster_slider = widgets.IntSlider(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=n_clusters - 1,\n",
        "    step=1,\n",
        "    description='Cluster No:',\n",
        "    continuous_update=False\n",
        ")\n",
        "sample_slider = widgets.IntSlider(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=0,  # will update based on the selected cluster\n",
        "    step=1,\n",
        "    description='Sample Idx:',\n",
        "    continuous_update=False\n",
        ")\n",
        "display(cluster_slider, sample_slider)\n",
        "\n",
        "# Function to visualize a PDB file using py3Dmol.\n",
        "def show_pdb(pdb_file: str, show_sidechains: bool = False, show_mainchains: bool = True):\n",
        "    view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "    try:\n",
        "        with open(pdb_file, 'r') as f:\n",
        "            pdb_content = f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {pdb_file}\")\n",
        "        return None\n",
        "    view.addModel(pdb_content, 'pdb')\n",
        "    view.setStyle({'cartoon': {'color': 'spectrum'}})\n",
        "\n",
        "    if show_sidechains:\n",
        "        BB = ['C', 'O', 'N']\n",
        "        view.addStyle({'and': [{'resn': [\"GLY\", \"PRO\"], 'invert': True}, {'atom': BB, 'invert': True}]},\n",
        "                      {'stick': {'colorscheme': \"WhiteCarbon\", 'radius': 0.3}})\n",
        "        view.addStyle({'and': [{'resn': \"GLY\"}, {'atom': 'CA'}]},\n",
        "                      {'sphere': {'colorscheme': \"WhiteCarbon\", 'radius': 0.3}})\n",
        "        view.addStyle({'and': [{'resn': \"PRO\"}, {'atom': ['C', 'O'], 'invert': True}]},\n",
        "                      {'stick': {'colorscheme': \"WhiteCarbon\", 'radius': 0.3}})\n",
        "    if show_mainchains:\n",
        "        BB = ['C', 'O', 'N', 'CA']\n",
        "        view.addStyle({'atom': BB}, {'stick': {'colorscheme': \"WhiteCarbon\", 'radius': 0.3}})\n",
        "\n",
        "    view.zoomTo()\n",
        "    return view\n",
        "\n",
        "# Helper to update the sample slider's maximum value based on the selected cluster.\n",
        "def update_sample_slider(cluster_no):\n",
        "    available_samples = list(clusters[cluster_no])\n",
        "    sample_slider.max = max(len(available_samples) - 1, 0)\n",
        "    # Reset sample_slider's value if it's out of range.\n",
        "    if sample_slider.value > sample_slider.max:\n",
        "        sample_slider.value = 0\n",
        "\n",
        "# Main function to update the viewer whenever widget values change.\n",
        "def update_view(change=None):\n",
        "    cluster_no = cluster_slider.value\n",
        "    update_sample_slider(cluster_no)\n",
        "    available_samples = list(clusters[cluster_no])\n",
        "    sample_idx = sample_slider.value\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(cluster_slider, sample_slider)\n",
        "\n",
        "    if sample_idx >= len(available_samples):\n",
        "        print(f\"Only {len(available_samples)} samples available in cluster {cluster_no}\")\n",
        "        return\n",
        "\n",
        "    chosen_sample = available_samples[sample_idx]\n",
        "    pdb_path = os.path.join(\"pdb_samples\", f\"{chosen_sample}.pdb\")\n",
        "\n",
        "    # Check if the file exists before attempting to open it.\n",
        "    if not os.path.exists(pdb_path):\n",
        "        print(f\"File not found: {pdb_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Displaying sample {sample_idx} from cluster {cluster_no}\")\n",
        "    view = show_pdb(pdb_path)\n",
        "    if view:\n",
        "        view.show()\n",
        "\n",
        "# Observe changes to the slider values.\n",
        "cluster_slider.observe(update_view, names='value')\n",
        "sample_slider.observe(update_view, names='value')\n",
        "\n",
        "# Trigger an initial update.\n",
        "update_view()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5EhJTP3tzcJ"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Reconstruct sidechains + Run MD relaxation\n",
        "#@markdown - `reconstruct_sidechains`: whether to reconstruct sidechains via `hpacker`\n",
        "#@markdown - `run_md`: check to run MD after sidechain reconstruction, otherwise only sidechain reconstruction is performed\n",
        "#@markdown - `md_protocol`: `LOCAL_MINIMIZATION`: fast but only resolves local problems ; `NVT_EQUIL`: slow but might resolve more severe issues\n",
        "#@markdown - `one_per_cluster`: Reconstruct sidechains / optionally run MD for only one sample within each foldseek cluster\n",
        "\n",
        "#@markdown **WARNING**: this step can be quite expensive depending on how many samples you have requested / sequence length. You may want to check the `one_per_cluster` option.\n",
        "\n",
        "reconstruct_sidechains = False #@param {type: \"boolean\"}\n",
        "run_md = True #@param {type:\"boolean\"}\n",
        "one_per_cluster = True #@param {type:\"boolean\"}\n",
        "md_protocol = \"LOCAL_MINIMIZATION\" #@param [\"LOCAL_MINIMIZATION\", \"NVT_EQUIL\"] {type:\"string\"}\n",
        "import bioemu.sidechain_relax\n",
        "bioemu.sidechain_relax.HPACKER_PYTHONBIN = '/usr/local/envs/hpacker/bin/python'\n",
        "\n",
        "from bioemu.sidechain_relax import main as sidechainrelax\n",
        "from bioemu.sidechain_relax import MDProtocol\n",
        "md_protocol = MDProtocol[md_protocol]\n",
        "os.environ['CONDA_PREFIX_1'] = '/usr/local/'\n",
        "\n",
        "if one_per_cluster:\n",
        "    topology_file = cluster_topology_file\n",
        "    trajectory_file = cluster_trajectory_file\n",
        "\n",
        "prefix = 'hpacker-openmm'\n",
        "if reconstruct_sidechains:\n",
        "    relaxed_dir = os.path.join(output_dir, prefix)\n",
        "    os.makedirs(relaxed_dir, exist_ok=True)\n",
        "    sidechainrelax(pdb_path=topology_file, xtc_path=trajectory_file,\n",
        "                  outpath=relaxed_dir, prefix=prefix, md_protocol=md_protocol,\n",
        "                  md_equil=run_md)\n",
        "    if run_md:\n",
        "        os.system(f'touch {relaxed_dir}/.RELAXED')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ny_9xpG2Nts"
      },
      "outputs": [],
      "source": [
        "#@title Package and download results\n",
        "from google.colab import files\n",
        "import tarfile\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "# Delete bioemu .npz batch files\n",
        "npz_files = glob(os.path.join(output_dir, \"*.npz\"))\n",
        "[os.unlink(npz) for npz in npz_files]\n",
        "\n",
        "# Add sidechain reconstruction files to output (#82)\n",
        "import shutil\n",
        "sidechain_topology = '/content/hpacker-openmm_sidechain_rec.pdb'\n",
        "sidechain_trajectory = '/content/hpacker-openmm_sidechain_rec.xtc'\n",
        "\n",
        "if os.path.exists(sidechain_topology) and os.path.exists(sidechain_trajectory):\n",
        "    shutil.copyfile(sidechain_topology, os.path.join(relaxed_dir, os.path.basename(sidechain_topology)))\n",
        "    shutil.copyfile(sidechain_trajectory, os.path.join(relaxed_dir, os.path.basename(sidechain_trajectory)))\n",
        "\n",
        "# Add small README\n",
        "README = \"\"\"\n",
        "# BioEmu Colab output:\n",
        "\n",
        "`samples.xtc` and `topology.pdb`: Trajectory and topology files of all drawn samples.\n",
        "`cluster_samples.xtc` and `cluster_topology.pdb`: Trajectory and topology files of clustered samples via\n",
        "                      foldseek using the parameters specified in the notebook.\n",
        "`foldseek_clusters.json`: Foldseek cluster assignment of all drawn samples\n",
        "`sequence.fasta`: FASTA file containing the sequence that was sampled\n",
        "`hpacker-openmm/`\n",
        "    |- `hpacker-openmm_sidechain_rec.pdb` and `hpacker-openmm_sidechain_rec.xtc`: Contain sidechain\n",
        "                      reconstructed samples via `hpacker`.\n",
        "    |- `hpacker-openmm_md_equil.pdb` and `hpacker-openmm_md_equil.xtc`: Contain MD-equilibrated samples\n",
        "                      after sidechain reconstruction.\n",
        "\n",
        "For issues, please visit the [`bioemu` GitHub repository](https://github.com/microsoft/bioemu)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(output_dir, \"README.md\"), \"w\") as readme_handle:\n",
        "    readme_handle.write(README)\n",
        "\n",
        "citations = {\n",
        "\"Lewis2024\": \"\"\"@article{Lewis2024,\n",
        "author =  {Lewis, Sarah and Hempel, Tim and Jim{\\'e}nez-Luna, Jos{\\'e} and Gastegger, Michael and Xie, Yu and Foong, Andrew Y. K. and Satorras, Victor Garc{\\'\\i}a and Abdin, Osama and Veeling, Bastiaan S. and Zaporozhets, Iryna and Chen, Yaoyi and Yang, Soojung and Schneuing, Arne and Nigam, Jigyasa and Barbero, Federico and Stimper, Vincent and Campbell, Andrew and Yim, Jason and Lienen, Marten and Shi, Yu and Zheng, Shuxin and Schulz, Hannes and Munir, Usman and Tomioka, Ryota and Clementi, Cecilia and No{\\'e}, Frank},\n",
        "doi = {10.1101/2024.12.05.626885},\n",
        "journal = {bioRxiv},\n",
        "title = {{Scalable emulation of protein equilibrium ensembles with generative deep learning}},\n",
        "year = {2025},\n",
        "comment = {BioEmu prediction}\n",
        "}\"\"\",\n",
        "\n",
        "\"Mirdita2021\": \"\"\"@article{Mirdita2022,\n",
        "author= {Mirdita, Milot and Schütze, Konstantin and Moriwaki, Yoshitaka and Heo, Lim and Ovchinnikov, Sergey and Steinegger, Martin },\n",
        "doi = {10.1038/s41592-022-01488-1},\n",
        "journal = {Nature Methods},\n",
        "title = {{ColabFold: Making Protein folding accessible to all}},\n",
        "year = {2022},\n",
        "comment = {ColabFold MMseqs2 MSA server}\n",
        "}\"\"\",\n",
        "\"VanKempen2023\": \"\"\"@article{VanKempen2023,\n",
        "author = {van Kempen, Michel and Kim, Stephanie S and Tumescheit, Charlotte and Mirdita, Milot and Lee, Jeongjae and Gilchrist, Cameron L M and S{\\\"{o}}ding, Johannes and Steinegger, Martin},\n",
        "doi = {10.1038/s41587-023-01773-0},\n",
        "journal = {Nature Biotechnology},\n",
        "title = {{Fast and accurate protein structure search with Foldseek}},\n",
        "year = {2023},\n",
        "comment = {Clustering structures}\n",
        "}\"\"\",\n",
        "}\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def write_bibtex(\n",
        "    result_dir: Path,\n",
        "    bibtex_file: str = \"cite.bibtex\",\n",
        ") -> Path:\n",
        "    to_cite = [\"Lewis2024\"]\n",
        "    to_cite += [\"Mirdita2021\"]\n",
        "    to_cite += [\"VanKempen2023\"]\n",
        "\n",
        "    bibtex_file = result_dir.joinpath(bibtex_file)\n",
        "    with bibtex_file.open(\"w\", encoding=\"utf-8\") as writer:\n",
        "        for i in to_cite:\n",
        "            writer.write(citations[i])\n",
        "            writer.write(\"\\n\")\n",
        "\n",
        "    print(f\"Found {len(to_cite)} citations for tools or databases\")\n",
        "    return bibtex_file\n",
        "\n",
        "write_bibtex(Path(output_dir))\n",
        "\n",
        "output_tarfile = f'/content/{jobname}.tar.gz'\n",
        "with tarfile.open(output_tarfile, 'w:gz') as tar_handle:\n",
        "    tar_handle.add(name=f'{output_dir}', arcname=os.path.basename(output_dir), recursive=True)\n",
        "\n",
        "files.download(output_tarfile)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
